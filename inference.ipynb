{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfdf34-bdea-4a1e-b688-87e9781977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "# import wandb\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import change_detection_pytorch as cdp\n",
    "from change_detection_pytorch.datasets import LEVIR_CD_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from change_detection_pytorch.utils.lr_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from change_detection_pytorch.datasets import ChangeDetectionDataModule\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac5f2c-6324-4ba4-bc02-39ade0bb4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd192_diff_e_real_160_b32_multisteplr/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_cdd/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_aug/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd_norm/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_oscd_norm/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd_norm_e400_lr4e-4/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_fa_oscd_norm/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd_norm_e300_lr2e-4/best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f9509-a8e3-45dc-9d2e-d2533f914a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "  Args = namedtuple('Args', ['experiment_name', 'backbone', 'encoder_weights', 'encoder_depth',\n",
    "                             'dataset_name', 'dataset_path', 'fusion', 'scale',\n",
    "                             'tile_size', 'mode', 'batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c631e7-bb76-405b-92f6-a8b05d16c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "  args = Args(experiment_name='tmp', fusion='diff', tile_size=192,\n",
    "              backbone='Swin-B', encoder_weights='geopile', encoder_depth=12,\n",
    "              dataset_name='OSCD', dataset_path='/mnt/sxtn/aerial/change/OSCD/', batch_size=116//4,\n",
    "              mode='vanilla', scale=None,\n",
    "              # mode='wo_train_aug', scale='4x'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ca86a-e210-48a7-844b-250fd88600b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # args = Args(experiment_name='tmp', fusion='diff', tile_size=192,\n",
    "  #             backbone='Swin-B', encoder_weights='geopile', encoder_depth=5,\n",
    "  #             dataset_name='CDD', dataset_path='/mnt/sxtn/aerial/change/CDD/Real/subset/', batch_size=2,\n",
    "  #             mode='vanilla', scale=None,\n",
    "  #             # mode='wo_train_aug', scale='8x'\n",
    "  #            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec387084-6c64-471a-9723-6eb70dbb9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # args = Args(experiment_name='tmp', fusion='diff', tile_size=192, \n",
    "  #             backbone='ibot-B', encoder_weights='million_aid', encoder_depth=12,\n",
    "  #             dataset_name='OSCD', dataset_path='/mnt/sxtn/aerial/change/OSCD/', batch_size=116//4,\n",
    "  #             mode='vanilla', scale=None,\n",
    "  #             # mode='wo_train_aug', scale='8x'\n",
    "  #            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44106c0b-5ce3-40c0-a3b9-6ed3d0bcaa11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = cdp.UPerNet(\n",
    "    encoder_depth=args.encoder_depth,\n",
    "    encoder_name=args.backbone, # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=args.encoder_weights, # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3, # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2, # model output channels (number of classes in your datasets)\n",
    "    siam_encoder=True, # whether to use a siamese encoder\n",
    "    fusion_form=args.fusion, # the form of fusing features from two branches. e.g. concat, sum, diff, or abs_diff.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c953914-af71-4601-b331-6d1c49347fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953b998-0a06-454e-8b41-fb640fea608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d3def-ee28-4da0-8280-68246a54caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'oscd' in args.dataset_name.lower():\n",
    "    datamodule = ChangeDetectionDataModule(args.dataset_path, patch_size=args.tile_size, mode=args.mode, scale=args.scale, batch_size=args.batch_size)\n",
    "    datamodule.setup()\n",
    "\n",
    "    valid_loader = datamodule.val_dataloader()\n",
    "    print(len(valid_loader))\n",
    "    data = {\n",
    "        'p': np.empty((0, 192, 192)),\n",
    "        't': np.empty((0, 192, 192)),\n",
    "        'f': []\n",
    "    }\n",
    "else:\n",
    "    print('CCD', args.dataset_name)\n",
    "    valid_dataset = LEVIR_CD_Dataset(f'{args.dataset_path}/val',\n",
    "                                    sub_dir_1='A',\n",
    "                                    sub_dir_2='B',\n",
    "                                    img_suffix='.jpg',\n",
    "                                    ann_dir=f'{args.dataset_path}/val/OUT',\n",
    "                                    debug=False,\n",
    "                                    seg_map_suffix='.jpg')\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    data = {\n",
    "        'p': np.empty((0, 256, 256)),\n",
    "        't': np.empty((0, 256, 256)),\n",
    "        'f': []\n",
    "    }\n",
    "loss = cdp.utils.losses.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6722f-6bf5-4119-96fb-d51542baa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from change_detection_pytorch.base.modules import Activation\n",
    "from change_detection_pytorch.utils import base\n",
    "from change_detection_pytorch.utils import functional as F\n",
    "\n",
    "class CustomMetric(base.Metric):\n",
    "    __name__ = 'custom'\n",
    "\n",
    "    def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "        self.threshold = threshold\n",
    "        self.activation = Activation(activation)\n",
    "        self.ignore_channels = ignore_channels\n",
    "\n",
    "    def forward(self, y_pr, y_gt):\n",
    "        y_pr = self.activation(y_pr)\n",
    "        data['p'] = np.concatenate([data['p'], y_pr.cpu().numpy()])\n",
    "        data['t'] = np.concatenate([data['t'], y_gt.cpu().numpy()])\n",
    "        \n",
    "        fscores = torch.tensor([F.f_score(p, g) for p, g in zip(y_pr, y_gt)])\n",
    "        # plt.figure(figsize=(4,2))\n",
    "        # plt.imshow((y_pr[0]*2+y_gt[0]).cpu().numpy(), cmap='nipy_spectral', vmax=4)\n",
    "        # plt.title(f\"F-score={fscores[0]:.3f}\")\n",
    "        # print(\"\\n\", y_pr.shape, y_gt.shape)\n",
    "        # print((y_pr*y_gt).sum(), y_pr.sum(), y_gt.sum())\n",
    "        return fscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4ffa3-d50a-45f7-9201-dbcfc35b9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_metrics = [\n",
    "    cdp.utils.metrics.Fscore(activation='argmax2d'),\n",
    "    cdp.utils.metrics.Precision(activation='argmax2d'),\n",
    "    cdp.utils.metrics.Recall(activation='argmax2d'),\n",
    "    CustomMetric(activation='argmax2d'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512457cc-f204-43f2-aedd-c2c4da8fab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_epoch = cdp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=our_metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_logs = valid_epoch.run(valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d52c30-efe7-495a-a4d8-56b39b4976c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['f'] = [y for x in valid_logs['filenames'] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2bac59-8dca-419b-be9d-88f12d38f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "coords = []\n",
    "for name in data['f']:\n",
    "    name = name.split('/')[-1]\n",
    "    _parts = name.split('_')\n",
    "    city = '_'.join(_parts[:-1])\n",
    "    coord = [int(t) for t in _parts[-1][1:-1].split(', ')]\n",
    "    cities.append(city)\n",
    "    coords.append(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc954ba-848b-45d4-ac33-ea12484d585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cities = set(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4035e-4271-42b6-8475-1210780f6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {city: {\n",
    "    't': np.zeros((1000, 1000)),\n",
    "    'p': np.zeros((1000, 1000)),\n",
    "} for city in unique_cities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069658c7-268d-4b4e-b4a3-aa24e21c1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city, coord, p, t in zip(cities, coords, data['p'], data['t']):\n",
    "    x1,y1,x2,y2 = coord\n",
    "    maps[city]['t'][y1:y2,x1:x2] = t\n",
    "    maps[city]['p'][y1:y2,x1:x2] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af337754-bfbb-4da3-8e89-279a52b85182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in tqdm(maps.keys()):\n",
    "    maps[city]['fscore'] = metrics.f1_score(maps[city]['t'].flatten(), maps[city]['p'].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170cc8d-5892-4b54-af6d-e4b8c6f522b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_f1 = metrics.f1_score(\n",
    "    np.concatenate([maps[city]['t'].flatten() for city in maps]),\n",
    "    np.concatenate([maps[city]['p'].flatten() for city in maps]), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fa4ba-e117-4206-b4e0-76a3fa65a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([maps[city]['fscore'] for city in maps]), micro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a27a24-3462-4cf6-bfaf-14e715e61f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in maps.keys():\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(maps[city]['p']*2 + maps[city]['t'], cmap='nipy_spectral', vmax=4)\n",
    "    plt.title(f\"{city} F-score: {maps[city]['fscore']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ef307-e749-4bec-a061-dfd3fc4abbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6f7ee-c234-49e1-b092-c7a5a379dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/mnt/sxtn/cd/satlas_model/sentinel2_swinb_si_rgb.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340d201-94a8-420f-b54c-52d54fc668a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9a18f-84e2-4899-a356-6aa57df2ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict = {}\n",
    "prefix='backbone.'\n",
    "needed='backbone'\n",
    "for key, value in checkpoint.items():\n",
    "    # Assure we're only keeping keys that we need for the current model component. \n",
    "    if not needed in key:\n",
    "        continue\n",
    "\n",
    "    # Update the key prefixes to match what the model expects.\n",
    "    if prefix is not None:\n",
    "        while key.count(prefix) > 0:\n",
    "            key = key.replace(prefix, '', 1)\n",
    "\n",
    "    new_state_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82725bc2-a90d-48a6-8530-1faef99a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.swin_v2_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fa16b-22fe-4ede-a036-62c6aa77f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0db08a-725f-4f68-9055-187a05afe88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f2618-62d1-4239-a98a-fd212ac70890",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969d4c0-498e-474d-b001-a568d73403ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f0522-c816-4609-8dea-c3c830e1f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(1024, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd42a8-1744-48fa-92e3-bc44d6bda9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290893c-304a-4ca2-963f-e1c3f5c4048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754bb4d5-a110-465d-9867-c3bd890067ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
