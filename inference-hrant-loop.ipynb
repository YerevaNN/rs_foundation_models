{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfdf34-bdea-4a1e-b688-87e9781977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "# import wandb\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import change_detection_pytorch as cdp\n",
    "from change_detection_pytorch.datasets import LEVIR_CD_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from change_detection_pytorch.utils.lr_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from change_detection_pytorch.datasets import ChangeDetectionDataModule\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c0c42-42b1-41a3-a8dc-acd39ea38ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac5f2c-6324-4ba4-bc02-39ade0bb4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd192_diff_e_real_160_b32_multisteplr/best_model.pth'\n",
    "# checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/debug_polylr/best_model.pth'\n",
    "# checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_oscd192_e160_b32_concat/best_model.pth'\n",
    "# checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_mid_oscd192_diff_e_160_multisteplr/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_polylr_e200_lr2e-4/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_cdd/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_aug/best_model.pth'\n",
    "checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/ibot/best_model.pth'\n",
    "# checkpoint_path = '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_aug/best_model.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35be00-fedf-4810-96fa-5ce014105381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    experiment_name: str = 'tmp'\n",
    "    backbone: str = 'Swin-B'\n",
    "    encoder_weights: str = 'geopile'\n",
    "    encoder_depth: int = 12\n",
    "    dataset_name: str = 'OSCD'\n",
    "    dataset_path: str = '/mnt/sxtn/aerial/change/OSCD/'\n",
    "    fusion: str = 'diff'\n",
    "    scale: str = None\n",
    "    tile_size: int = 192\n",
    "    mode: str = 'vanilla'\n",
    "    batch_size: int = 116 // 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8be844-3c54-436e-98b7-583a6d9e381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = ['1x', '2x', '4x', '8x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96adbe-e337-4bf5-8624-9b91f7b1e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/gfm/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_aug/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/ibot/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_aug/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_cdd/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/gfm_cdd_aug/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_cdd/best_model.pth',\n",
    "    '/auto/home/ani/change_detection.pytorch/checkpoints/ibot_cdd_aug/best_model.pth',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198c21f-16e9-4135-acae-7366d0c27d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_bitwise(y_true, y_pred):\n",
    "    TP = np.bitwise_and(y_true, y_pred).sum()\n",
    "    FP = np.bitwise_and(y_pred, np.logical_not(y_true)).sum()\n",
    "    FN = np.bitwise_and(np.logical_not(y_pred), y_true).sum()\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-10)\n",
    "    recall = TP / (TP + FN + 1e-10)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bf472-0c36-4d99-aa7f-76f841d420f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint_path in checkpoints:\n",
    "    results[checkpoint_path] = {}\n",
    "    for scale in scales:\n",
    "        args = Args()  # Create an instance with default values\n",
    "        if scale != '1x':\n",
    "            args.scale = scale\n",
    "            args.mode = 'wo_train_aug'\n",
    "    \n",
    "        if 'ibot' in checkpoint_path:\n",
    "            args.backbone = 'ibot-B'\n",
    "            args.encoder_weights = 'million_aid'\n",
    "            args.encoder_depth = 12\n",
    "\n",
    "        if '_cdd' in checkpoint_path:\n",
    "            args.dataset_name = 'CDD'\n",
    "            args.dataset_path = '/mnt/sxtn/aerial/change/CDD/Real/subset/'\n",
    "            args.batch_size = 200\n",
    "            args.tile_size = 256 # it doesn't use\n",
    "            \n",
    "        print(args)\n",
    "        \n",
    "        # args = Args(experiment_name='tmp', fusion='diff', tile_size=192,\n",
    "        #             backbone='Swin-B', encoder_weights='geopile', encoder_depth=5,\n",
    "        #             dataset_name='CDD', dataset_path='/mnt/sxtn/aerial/change/CDD/Real/subset/', batch_size=2,\n",
    "        #             mode='vanilla', scale=None,\n",
    "        #             # mode='wo_train_aug', scale='8x'\n",
    "        #            )\n",
    "        \n",
    "        # args = Args(experiment_name='tmp', fusion='diff', tile_size=192, \n",
    "        #             backbone='ibot-B', encoder_weights='million_aid', encoder_depth=12,\n",
    "        #             dataset_name='OSCD', dataset_path='/mnt/sxtn/aerial/change/OSCD/', batch_size=116//4,\n",
    "        #             # mode='vanilla', scale=None,\n",
    "        #             mode='wo_train_aug', scale='8x'\n",
    "        #            )\n",
    "        \n",
    "        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model = cdp.UPerNet(\n",
    "            encoder_depth=args.encoder_depth,\n",
    "            encoder_name=args.backbone, # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=args.encoder_weights, # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3, # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=2, # model output channels (number of classes in your datasets)\n",
    "            siam_encoder=True, # whether to use a siamese encoder\n",
    "            fusion_form=args.fusion, # the form of fusing features from two branches. e.g. concat, sum, diff, or abs_diff.\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        model.load_state_dict(checkpoint.state_dict())\n",
    "        \n",
    "        if 'oscd' in args.dataset_name.lower():\n",
    "            datamodule = ChangeDetectionDataModule(args.dataset_path, patch_size=args.tile_size, \n",
    "                                                   mode=args.mode, scale=args.scale, batch_size=args.batch_size)\n",
    "            datamodule.setup()\n",
    "        \n",
    "            valid_loader = datamodule.val_dataloader()\n",
    "            print(len(valid_loader))\n",
    "            data = {\n",
    "                'p': np.empty((0, 192, 192), dtype='uint8'),\n",
    "                't': np.empty((0, 192, 192), dtype='uint8'),\n",
    "                'f': []\n",
    "            }\n",
    "        else:\n",
    "            print('CCD', args.dataset_name)\n",
    "            valid_dataset = LEVIR_CD_Dataset(f'{args.dataset_path}/test',\n",
    "                                            sub_dir_1='A',\n",
    "                                            sub_dir_2='B' if scale == '1x' else f'B_{scale}',\n",
    "                                            img_suffix='.jpg',\n",
    "                                            ann_dir=f'{args.dataset_path}/test/OUT',\n",
    "                                            debug=False,\n",
    "                                            seg_map_suffix='.jpg')\n",
    "        \n",
    "            valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "            data = {\n",
    "                'p': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                't': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                'f': []\n",
    "            }\n",
    "        loss = cdp.utils.losses.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        from change_detection_pytorch.base.modules import Activation\n",
    "        from change_detection_pytorch.utils import base\n",
    "        from change_detection_pytorch.utils import functional as F\n",
    "        \n",
    "        class CustomMetric(base.Metric):\n",
    "            __name__ = 'custom'\n",
    "        \n",
    "            def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "                self.eps = eps\n",
    "                self.threshold = threshold\n",
    "                self.activation = Activation(activation)\n",
    "                self.ignore_channels = ignore_channels\n",
    "        \n",
    "            def forward(self, y_pr, y_gt):\n",
    "                y_pr = self.activation(y_pr)\n",
    "                data['p'] = np.concatenate([data['p'], y_pr.cpu().numpy().astype('uint8')])\n",
    "                data['t'] = np.concatenate([data['t'], y_gt.cpu().numpy().astype('uint8')])\n",
    "                \n",
    "                fscores = torch.tensor([F.f_score(p, g) for p, g in zip(y_pr, y_gt)])\n",
    "                # plt.figure(figsize=(4,2))\n",
    "                # plt.imshow((y_pr[0]*2+y_gt[0]).cpu().numpy(), cmap='nipy_spectral', vmax=4)\n",
    "                # plt.title(f\"F-score={fscores[0]:.3f}\")\n",
    "                # print(\"\\n\", y_pr.shape, y_gt.shape)\n",
    "                # print((y_pr*y_gt).sum(), y_pr.sum(), y_gt.sum())\n",
    "                return fscores.mean()\n",
    "        \n",
    "        our_metrics = [\n",
    "            cdp.utils.metrics.Fscore(activation='argmax2d'),\n",
    "            cdp.utils.metrics.Precision(activation='argmax2d'),\n",
    "            cdp.utils.metrics.Recall(activation='argmax2d'),\n",
    "            CustomMetric(activation='argmax2d'),\n",
    "        ]\n",
    "        \n",
    "        valid_epoch = cdp.utils.train.ValidEpoch(\n",
    "            model,\n",
    "            loss=loss,\n",
    "            metrics=our_metrics,\n",
    "            device=DEVICE,\n",
    "            verbose=True,\n",
    "        )\n",
    "        \n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "        \n",
    "        if 'oscd' in args.dataset_name.lower():\n",
    "            data['f'] = [y for x in valid_logs['filenames'] for y in x]\n",
    "            \n",
    "            cities = []\n",
    "            coords = []\n",
    "            for name in data['f']:\n",
    "                name = name.split('/')[-1]\n",
    "                _parts = name.split('_')\n",
    "                city = '_'.join(_parts[:-1])\n",
    "                coord = [int(t) for t in _parts[-1][1:-1].split(', ')]\n",
    "                cities.append(city)\n",
    "                coords.append(coord)\n",
    "            \n",
    "            unique_cities = set(cities)\n",
    "            \n",
    "            maps = {city: {\n",
    "                't': np.zeros((1000, 1000)),\n",
    "                'p': np.zeros((1000, 1000)),\n",
    "            } for city in unique_cities}\n",
    "            \n",
    "            for city, coord, p, t in zip(cities, coords, data['p'], data['t']):\n",
    "                x1,y1,x2,y2 = coord\n",
    "                maps[city]['t'][y1:y2,x1:x2] = t\n",
    "                maps[city]['p'][y1:y2,x1:x2] = p\n",
    "            \n",
    "            for city in tqdm(maps.keys()):\n",
    "                maps[city]['fscore'] = metrics.f1_score(maps[city]['t'].flatten(), maps[city]['p'].flatten())\n",
    "            \n",
    "            macro_f1 = np.mean([maps[city]['fscore'] for city in maps])\n",
    "            \n",
    "            micro_f1 = metrics.f1_score(\n",
    "                np.concatenate([maps[city]['t'].flatten() for city in maps]),\n",
    "                np.concatenate([maps[city]['p'].flatten() for city in maps]), \n",
    "            )\n",
    "        else:\n",
    "            fscores = []\n",
    "            maps_t = []\n",
    "            maps_p = []\n",
    "            for p, t in tqdm(zip(data['p'], data['t'])):\n",
    "                if p.sum() + t.sum() == 0:\n",
    "                    fscores.append(0)\n",
    "                else:\n",
    "                    f1_real = metrics.f1_score(t.flatten(), p.flatten())\n",
    "                    # f1_ours = f1_bitwise(t.flatten(), p.flatten())\n",
    "                    fscores.append(\n",
    "                        f1_real\n",
    "                    )\n",
    "                maps_t.append(t)\n",
    "                maps_p.append(p)\n",
    "            macro_f1 = np.mean(fscores)\n",
    "            maps_t = np.vstack(maps_t)\n",
    "            maps_p = np.vstack(maps_p)\n",
    "            print(maps_t.shape, maps_p.shape)\n",
    "\n",
    "            print(maps_t)\n",
    "            print(maps_t.dtype)\n",
    "            micro_f1 = f1_bitwise(maps_t, maps_p)\n",
    "            maps = {'t':maps_t, 'p':maps_p}\n",
    "            \n",
    "        \n",
    "        print(checkpoint_path, scale)\n",
    "        print(macro_f1, micro_f1)\n",
    "    \n",
    "        results[checkpoint_path][scale] = {\n",
    "            'maps': maps,\n",
    "            'micro_f1': micro_f1,\n",
    "            'macro_f1': macro_f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eff6a6-ac84-44e8-a5f4-131501f3c09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7ae2f-3eaa-4eb8-aeec-66f220362ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print(checkpoint)\n",
    "    for scale in scales:\n",
    "        print(f\"{scale} macro F1 = {results[checkpoint][scale]['macro_f1']:.3f}  micro-F1 = {results[checkpoint][scale]['micro_f1']:.3f}\")\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59964303-3006-41fa-939f-eac981d3f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print(checkpoint)\n",
    "    for scale in ['8x', '4x', '2x', '1x']:\n",
    "        print(f\",{results[checkpoint][scale]['micro_f1']:.3f}\", end='')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a27a24-3462-4cf6-bfaf-14e715e61f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in maps.keys():\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(maps[city]['p']*2 + maps[city]['t'], cmap='nipy_spectral', vmax=4)\n",
    "    plt.title(f\"{city} F-score: {maps[city]['fscore']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ef307-e749-4bec-a061-dfd3fc4abbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
