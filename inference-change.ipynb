{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfdf34-bdea-4a1e-b688-87e9781977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import change_detection_pytorch as cdp\n",
    "from change_detection_pytorch.datasets import LEVIR_CD_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from change_detection_pytorch.datasets import ChangeDetectionDataModule\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c0c42-42b1-41a3-a8dc-acd39ea38ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35be00-fedf-4810-96fa-5ce014105381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    experiment_name: str = 'tmp'\n",
    "    backbone: str = 'Swin-B'\n",
    "    encoder_weights: str = 'geopile'\n",
    "    encoder_depth: int = 12\n",
    "    dataset_name: str = 'OSCD'\n",
    "    dataset_path: str = '/mnt/sxtn/aerial/change/OSCD/'\n",
    "    fusion: str = 'diff'\n",
    "    scale: str = None\n",
    "    tile_size: int = 192\n",
    "    mode: str = 'vanilla'\n",
    "    batch_size: int = 116 // 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8be844-3c54-436e-98b7-583a6d9e381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = ['1x', '2x', '4x', '8x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96adbe-e337-4bf5-8624-9b91f7b1e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [] #path_to_finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198c21f-16e9-4135-acae-7366d0c27d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_bitwise(y_true, y_pred):\n",
    "    TP = np.bitwise_and(y_true, y_pred).sum()\n",
    "    FP = np.bitwise_and(y_pred, np.logical_not(y_true)).sum()\n",
    "    FN = np.bitwise_and(np.logical_not(y_pred), y_true).sum()\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-10)\n",
    "    recall = TP / (TP + FN + 1e-10)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6672f-bd51-4fd1-aee0-2b7b063d32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84414cf-471c-459d-9d9b-6bb2db30dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from change_detection_pytorch.base.modules import Activation\n",
    "from change_detection_pytorch.utils import base\n",
    "from change_detection_pytorch.utils import functional as F\n",
    "\n",
    "class CustomMetric(base.Metric):\n",
    "            __name__ = 'custom'\n",
    "        \n",
    "            def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n",
    "                super().__init__(**kwargs)\n",
    "                self.eps = eps\n",
    "                self.threshold = threshold\n",
    "                self.activation = Activation(activation)\n",
    "                self.ignore_channels = ignore_channels\n",
    "        \n",
    "            def forward(self, y_pr, y_gt):\n",
    "                y_pr = self.activation(y_pr)\n",
    "                data['p'] = np.concatenate([data['p'], y_pr.cpu().numpy().astype('uint8')])\n",
    "                data['t'] = np.concatenate([data['t'], y_gt.cpu().numpy().astype('uint8')])\n",
    "                \n",
    "                fscores = torch.tensor([F.f_score(p, g) for p, g in zip(y_pr, y_gt)])\n",
    "                return fscores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171c99a-4063-4b3b-9c2c-7b82643b7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint_path in checkpoints:\n",
    "    results[checkpoint_path] = {}\n",
    "    for scale in scales:\n",
    "        args = Args()  # Create an instance with default values\n",
    "        if scale != '1x':\n",
    "            args.scale = scale\n",
    "            args.mode = 'wo_train_aug'\n",
    "    \n",
    "        if 'ibot' in checkpoint_path:\n",
    "            args.backbone = 'ibot-B'\n",
    "            args.encoder_weights = 'million_aid'\n",
    "            args.encoder_depth = 12\n",
    "        elif 'satlas' in checkpoint_path:\n",
    "            args.backbone = 'Swin-B'\n",
    "            args.encoder_weights = 'satlas'\n",
    "            args.encoder_depth = 12\n",
    "\n",
    "        if 'cdd' in checkpoint_path:\n",
    "            args.dataset_name = 'CDD'\n",
    "            args.dataset_path = #path_to_dataset\n",
    "            args.batch_size = 32\n",
    "            args.tile_size = 256 # it doesn't use\n",
    "        elif 'levir' in checkpoint_path:\n",
    "            args.dataset_name = 'LEVIR_CD'\n",
    "            args.dataset_path = #path_to_dataset\n",
    "            args.batch_size = 32\n",
    "            args.tile_size = 256 # it doesn't use\n",
    "            \n",
    "        print(args)\n",
    "        \n",
    "        # DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        DEVICE = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # args.fusion = 'concat' # comment this for other models\n",
    "        \n",
    "        model = cdp.UPerNet(\n",
    "            encoder_depth=args.encoder_depth,\n",
    "            encoder_name=args.backbone, # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=args.encoder_weights, # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=3, # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=2, # model output channels (number of classes in your datasets)\n",
    "            siam_encoder=True, # whether to use a siamese encoder\n",
    "            fusion_form=args.fusion, # the form of fusing features from two branches. e.g. concat, sum, diff, or abs_diff.\n",
    "        )\n",
    "\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        model.load_state_dict(checkpoint.state_dict())\n",
    "\n",
    "        \n",
    "        if 'cdd' in args.dataset_name.lower():\n",
    "            print('CDD', args.dataset_name)\n",
    "            valid_dataset = LEVIR_CD_Dataset(f'{args.dataset_path}/test',\n",
    "                                            sub_dir_1='A',\n",
    "                                            sub_dir_2='B' if scale == '1x' else f'B_{scale}',\n",
    "                                            img_suffix='.jpg',\n",
    "                                            ann_dir=f'{args.dataset_path}/test/OUT',\n",
    "                                            debug=False,\n",
    "                                            seg_map_suffix='.jpg')\n",
    "        \n",
    "            valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "            data = {\n",
    "                'p': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                't': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                'f': []\n",
    "            }\n",
    "\n",
    "        elif 'levir' in args.dataset_name.lower():\n",
    "            print('LEVIR', args.dataset_name)\n",
    "            valid_dataset = LEVIR_CD_Dataset(f'{args.dataset_path}/test',\n",
    "                                            sub_dir_1='A_cut',\n",
    "                                            sub_dir_2='B_cut' if scale == '1x' else f'B_cut_{scale}',\n",
    "                                            img_suffix='.png',\n",
    "                                            #ann_dir=f'{args.dataset_path}/test/OUT',\n",
    "                                            ann_dir=f'{args.dataset_path}/test/OUT_cut',\n",
    "                                            debug=False,\n",
    "                                            test_mode=True,\n",
    "                                            seg_map_suffix='.png')\n",
    "        \n",
    "            valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "            data = {\n",
    "                'p': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                't': np.empty((0, 256, 256), dtype='uint8'),\n",
    "                'f': []\n",
    "            }\n",
    "            \n",
    "        loss = cdp.utils.losses.CrossEntropyLoss()\n",
    "        \n",
    "        our_metrics = [\n",
    "            cdp.utils.metrics.Fscore(activation='argmax2d'),\n",
    "            cdp.utils.metrics.Precision(activation='argmax2d'),\n",
    "            cdp.utils.metrics.Recall(activation='argmax2d'),\n",
    "            CustomMetric(activation='argmax2d'),\n",
    "        ]\n",
    "        \n",
    "        valid_epoch = cdp.utils.train.ValidEpoch(\n",
    "            model,\n",
    "            loss=loss,\n",
    "            metrics=our_metrics,\n",
    "            device=DEVICE,\n",
    "            verbose=True,\n",
    "        )\n",
    "        \n",
    "        valid_logs = valid_epoch.run(valid_loader)\n",
    "                \n",
    "        if 'cdd' in args.dataset_name.lower() or 'levir' in args.dataset_name.lower():\n",
    "            fscores = []\n",
    "            maps_t = []\n",
    "            maps_p = []\n",
    "            for p, t in tqdm(zip(data['p'], data['t'])):\n",
    "                if p.sum() + t.sum() == 0:\n",
    "                    fscores.append(0)\n",
    "                else:\n",
    "                    f1_real = metrics.f1_score(t.flatten(), p.flatten())\n",
    "                    # f1_ours = f1_bitwise(t.flatten(), p.flatten())\n",
    "                    fscores.append(\n",
    "                        f1_real\n",
    "                    )\n",
    "                maps_t.append(t)\n",
    "                maps_p.append(p)\n",
    "            macro_f1 = np.mean(fscores)\n",
    "            maps_t = np.vstack(maps_t)\n",
    "            maps_p = np.vstack(maps_p)\n",
    "            print(maps_t.shape, maps_p.shape)\n",
    "\n",
    "            print(maps_t)\n",
    "            print(maps_t.dtype)\n",
    "            micro_f1 = f1_bitwise(maps_t, maps_p)\n",
    "            maps = {'t':maps_t, 'p':maps_p}\n",
    "            \n",
    "        \n",
    "        print(checkpoint_path, scale)\n",
    "        print(macro_f1, micro_f1)\n",
    "    \n",
    "        results[checkpoint_path][scale] = {\n",
    "            'maps': maps,\n",
    "            'micro_f1': micro_f1,\n",
    "            'macro_f1': macro_f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c63fd6-4241-4126-bfaf-479aff905247",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print(checkpoint)\n",
    "    for scale in scales:\n",
    "        print(f\"{scale} macro F1 = {results[checkpoint][scale]['macro_f1']:.3f}  micro-F1 = {results[checkpoint][scale]['micro_f1']:.3f}\")\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59964303-3006-41fa-939f-eac981d3f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    print(checkpoint)\n",
    "    for scale in ['8x', '4x', '2x', '1x']:\n",
    "        print(f\",{results[checkpoint][scale]['micro_f1']:.3f}\", end='')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a27a24-3462-4cf6-bfaf-14e715e61f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f47d6-d79e-4bf3-8db7-d360b361f999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
